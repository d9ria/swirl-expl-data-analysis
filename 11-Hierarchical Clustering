In the given plot which pair points would you first cluster? Use distance as the metric.
1: 5 and 6
2: 1 and 4
3: 7 and 8
4: 10 and 12

Selection: 1

| Excellent job!

> dist(dataFrame)
            1          2          3          4          5          6          7          8          9         10         11
2  0.34120511                                                                                                              
3  0.57493739 0.24102750                                                                                                   
4  0.26381786 0.52578819 0.71861759                                                                                        
5  1.69424700 1.35818182 1.11952883 1.80666768                                                                             
6  1.65812902 1.31960442 1.08338841 1.78081321 0.08150268                                                                  
7  1.49823399 1.16620981 0.92568723 1.60131659 0.21110433 0.21666557                                                       
8  1.99149025 1.69093111 1.45648906 2.02849490 0.61704200 0.69791931 0.65062566                                            
9  2.13629539 1.83167669 1.67835968 2.35675598 1.18349654 1.11500116 1.28582631 1.76460709                                 
10 2.06419586 1.76999236 1.63109790 2.29239480 1.23847877 1.16550201 1.32063059 1.83517785 0.14090406                      
11 2.14702468 1.85183204 1.71074417 2.37461984 1.28153948 1.21077373 1.37369662 1.86999431 0.11624471 0.08317570           
12 2.05664233 1.74662555 1.58658782 2.27232243 1.07700974 1.00777231 1.17740375 1.66223814 0.10848966 0.19128645 0.20802789

| Excellent work!

| From the output of dist, what is the minimum distance between two points?

1: 0.0815
2: 0.08317
3: 0.1085
4: -0.0700

Selection: 1

| You are amazing!

| Looking at the picture, what would be another good pair of points to put in another cluster given that 5 and 6 are already clustered?

1: 10 and 11
2: 1 and 4
3: 7 and 8
4: 7 and the cluster containing 5 ad 6

Selection: 
Enter an item from the menu, or 0 to exit
Selection: 1

| Keep working like that and you'll get there!

hc <- hclust(distxy)
plot(hc)
plot(as.dendrogram(hc))
abline(h=1.5,col="blue")
abline(h=.4,col="red")

> dist(dFsm)
         1        2
2 2.028495         
3 2.374620 1.869994

| You got it!

| Which type of linkage did hclust() use to agglomerate clusters?

1: average
2: complete

Selection: 2

| That's a job well done!

heatmap(dataMatrix,col=cm.colors(25))
heatmap(mt)

> mt
                  mpg cyl  disp  hp drat    wt
Dodge Challenger 15.5   8 318.0 150 2.76 3.520
AMC Javelin      15.2   8 304.0 150 3.15 3.435
Camaro Z28       13.3   8 350.0 245 3.73 3.840
Pontiac Firebird 19.2   8 400.0 175 3.08 3.845
Fiat X1-9        27.3   4  79.0  66 4.08 1.935
Porsche 914-2    26.0   4 120.3  91 4.43 2.140
Lotus Europa     30.4   4  95.1 113 3.77 1.513
Ford Pantera L   15.8   8 351.0 264 4.22 3.170
Ferrari Dino     19.7   6 145.0 175 3.62 2.770
Maserati Bora    15.0   8 301.0 335 3.54 3.570
Volvo 142E       21.4   4 121.0 109 4.11 2.780

plot(denmt)

> distmt
                 Dodge Challenger AMC Javelin Camaro Z28 Pontiac Firebird Fiat X1-9 Porsche 914-2 Lotus Europa Ford Pantera L Ferrari Dino
AMC Javelin              14.00890                                                                                                         
Camaro Z28              100.27404   105.57041                                                                                             
Pontiac Firebird         85.80733    99.28330   86.22779                                                                                  
Fiat X1-9               253.64640   240.51305  325.11191        339.12867                                                                 
Porsche 914-2           206.63309   193.29419  276.87318        292.15588  48.29642                                                       
Lotus Europa            226.48724   212.74240  287.59666        311.37656  49.78046      33.75246                                         
Ford Pantera L          118.69012   123.31494   19.20778        101.66275 336.65679     288.56998    297.51961                            
Ferrari Dino            174.86264   161.03078  216.72821        255.01117 127.67016      87.81135     80.33743      224.44761             
Maserati Bora           185.78176   185.02489  102.48902        188.19917 349.02042     303.85577    303.20992       86.84620    223.52346
Volvo 142E              201.35337   187.68535  266.49555        286.74036  60.40302      18.60543     27.74042      277.43923     70.27895
                 Maserati Bora
AMC Javelin                   
Camaro Z28                    
Pontiac Firebird              
Fiat X1-9                     
Porsche 914-2                 
Lotus Europa                  
Ford Pantera L                
Ferrari Dino                  
Maserati Bora                 
Volvo 142E           289.02233

| You nailed it! Good job!

| What is the purpose of hierarchical clustering?

1: Present a finished picture
2: None of the others
3: Give an idea of the relationships between variables or observations
4: Inspire other researchers

Selection: 3

| Great job!

  |=====================================================================================================================               |  89%
| True or False? When you're doing hierarchical clustering there are strict rules that you MUST follow.

1: False
2: True

Selection: 1

| Keep up the great work!

  |=======================================================================================================================             |  90%
| True or False? There's only one way to measure distance.

1: False
2: True

Selection: 1

| That's the answer I was looking for.

  |=========================================================================================================================           |  92%
| True or False? Complete linkage is a method of computing distances between clusters.

1: False
2: True

Selection: 2

| You nailed it! Good job!

  |===========================================================================================================================         |  94%
| True or False? Average linkage uses the maximum distance between points of two clusters as the distance between those clusters.

1: True
2: False

Selection: 2

| Excellent work!

  |==============================================================================================================================      |  95%
| True or False? The number of clusters you derive from your data depends on the distance at which you choose to cut it.

1: True
2: False

Selection: 1

| You got it right!

  |================================================================================================================================    |  97%
| True or False? Once you decide basics, such as defining a distance metric and linkage method, hierarchical clustering is deterministic.

1: False
2: True

Selection: 2

| Excellent job!

  |==================================================================================================================================  |  98%
| Congratulations! We hope this lesson didn't fluster you or get you too heated!
