Selection: 14
| Attempting to load lesson dependencies...
| Package ‘fields’ loaded correctly!
| Package ‘jpeg’ loaded correctly!
| Package ‘datasets’ loaded correctly!
| | 0%
| Clustering_Example. (Slides for this and other Data Science courses may be found at github
| https://github.com/DataScienceSpecialization/courses/. If you care to use them, they must be
downloaded as a zip file and viewed locally.
| This lesson corresponds to 04_ExploratoryAnalysis/clusteringExample.)
...
|== | 2%
| In this lesson we&#39;ll apply some of the analytic techniques we learned in this course to data from the
University of California, Irvine.

| Specifically, the data we&#39;ll use is from UCI&#39;s Center for Machine Learning and Intelligent Systems. You
can find out more about the data
| at http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones. As this
address indicates, the data involves
| smartphones and recognizing human activity. Cool, right?
...
|==== | 3%
| Our goal is to show you how to use exploratory data analysis to point you in fruitful directions of
research, that is, towards answerable
| questions. Exploratory data analysis is a &quot;rough cut&quot; or filter which helps you to find the most beneficial
areas of questioning so you
| can set your priorities accordingly.
...
|====== | 5%
| We also hope to show you that &quot;real-world&quot; research isn&#39;t always neat and well-defined like textbook
questions with clearcut answers.
...
|======== | 6%
| We&#39;ve loaded data from this study for you in a matrix called ssd. Run the R command dim now to see
its dimensions.
&gt;
&gt; dim(ssd)
[1] 7352 563
| You are really on a roll!
|========== | 8%
| Wow - ssd is pretty big, 7352 observations, each of 563 variables. Don&#39;t worry we&#39;ll only use a small
portion of this &quot;Human Activity
| Recognition database&quot;.
...
|============ | 9%
| The study creating this database involved 30 volunteers &quot;performing activities of daily living (ADL) while
carrying a waist-mounted
| smartphone with embedded inertial sensors. ... Each person performed six activities ... wearing a
smartphone (Samsung Galaxy S II) on the
| waist. ... The experiments have been video-recorded to label the data manually. The obtained dataset
has been randomly partitioned into
| two sets, where 70% of the volunteers was selected for generating the training data and 30% the test
data.&quot;
...
|============== | 11%
| Use the R command names with just the last two columns (562 and 563) of ssd to see what data they
contain.
&gt; names(ssd[,562:563])
[1] &quot;subject&quot; &quot;activity&quot;
| All that hard work is paying off!
|================ | 12%

| These last 2 columns contain subject and activity information. We saw above that the gathered data had
&quot;been randomly partitioned into
| two sets, where 70% of the volunteers was selected for generating the training data and 30% the test
data.&quot; Run the R command table with
| ssd$subject as its argument to see if the data in ssd contains training or test data.
&gt; table( ssd$subject)
1 3 5 6 7 8 11 14 15 16 17 19 21 22 23 25 26 27 28 29 30
347 341 302 325 308 281 316 323 328 366 368 360 408 321 372 409 392 376 382 344 383
| You are quite good my friend!
|================== | 14%
| From the number of subjects, would you infer that ssd contains training or test data?
1: training
2: test
Selection: 2
| Not exactly. Give it another go.
| Count the number of subjects represented here. Does this represent 70% or 30% of the total subject
population?
1: test
2: training
Selection: 2
| You are doing so well!
|==================== | 16%
| So ssd contains only training data. If you ran the R command sum with table(ssd$subject) as its
argument, what would the number you get
| back represent?
1: the number of columns in ssd
2: the number of rows and columns of ssd
3: Huh?
4: the number of rows in ssd
Selection: 3
| That&#39;s not exactly what I&#39;m looking for. Try again.
| Each row was labeled with one subject and the output from table(ssd$subject) told you how many rows
each subject contributed to the
| study.
1: the number of rows and columns of ssd
2: the number of columns in ssd
3: Huh?
4: the number of rows in ssd
Selection: 4
| You are doing so well!
|====================== | 17%
| Try it now (running sum on table(ssd$subject))to see if you get 7352, the number of rows in ssd, as a
result.

&gt; sum(table(ssd$subject))
[1] 7352
| You are doing so well!
|======================== |
19%
| So we&#39;re looking at training data from a machine learning repository. We can infer that this data is
supposed to train machines to
| recognize activity collected from the accelerometers and gyroscopes built into the smartphones that the
subjects had strapped to their
| waists. Run the R command table on ssd$activity to see what activities have been characterized by this
data.
&gt; table (ssd$activity)
laying sitting standing walk walkdown walkup
1407 1286 1374 1226 986 1073
| That&#39;s the answer I was looking for.
|========================== |
20%
| We have 6 activities, 3 passive (laying, standing and sitting) and 3 active which involve walking. If you
ran the R command sum with
| table(ssd$activity) as its argument, what would the number you get back represent?
1: Huh?
2: the number of rows and columns of ssd
3: the number of columns in ssd
4: the number of rows in ssd
Selection: 4
| All that hard work is paying off!
|============================ |
22%
| Because it&#39;s training data, each row is labeled with the correct activity (from the 6 possible) and
associated with the column
| measurements (from the accelerometer and gyroscope). We&#39;re interested in questions such as, &quot;Is the
correlation between the measurements
| and activities good enough to train a machine?&quot; so that &quot;Given a set of 561 measurements, would a
trained machine be able to determine
| which of the 6 activities the person was doing?&quot;
...
|============================== |
23%
| First, let&#39;s massage the data a little so it&#39;s easier to work with. We&#39;ve already run the R command
transform on the data so that
| activities are factors. This will let us color code them when we generate plots. Let&#39;s look at only the first
subject (numbered 1).
| Create the variable sub1 by assigning to it the output of the R command subset with ssd as the first
argument and the boolean, subject
| equal to 1, as the second.
&gt; sub1 &lt;- subset(ssdm, subject=1)
Error: object &#39;ssdm&#39; not found
&gt; sub1 &lt;- subset(ssd, subject=1)
Warning message:

In subset.data.frame(ssd, subject = 1) :
extra argument ‘subject’ will be disregarded
| You almost had it, but not quite. Try again. Or, type info() for more options.
| Type sub1 &lt;- subset(ssd, subject == 1) at the command prompt.
&gt; sub1 &lt;- subset(ssd, subject==1)
| That&#39;s correct!
|================================
| 25%
| Look at the dimensions of sub1 now.
&gt; dim(sub1)
[1] 347 563
| You are amazing!
|===================================
| 27%
| So sub1 has fewer than 400 rows now, but still a lot of columns which contain measurements. Use
names on the first 12 columns of sub1 to
| see what kind of data we have.
&gt; names(sub1[,1:12])
[1] &quot;tBodyAcc.mean...X&quot; &quot;tBodyAcc.mean...Y&quot; &quot;tBodyAcc.mean...Z&quot; &quot;tBodyAcc.std...X&quot; &quot;tBodyAcc.std...Y&quot;
&quot;tBodyAcc.std...Z&quot;
[7] &quot;tBodyAcc.mad...X&quot; &quot;tBodyAcc.mad...Y&quot; &quot;tBodyAcc.mad...Z&quot; &quot;tBodyAcc.max...X&quot;
&quot;tBodyAcc.max...Y&quot; &quot;tBodyAcc.max...Z&quot;
| That&#39;s a job well done!
|=====================================
| 28%
| We see X, Y, and Z (3 dimensions) of different aspects of body acceleration measurements, such as
mean and standard deviation. Let&#39;s do
| some comparisons of activities now by looking at plots of mean body acceleration in the X and Y
directions. Call the function myedit with
| the string &quot;showXY.R&quot; to see the code generating the plots. Make sure your cursor is back in the console
window before you hit any more
| buttons.
&gt; myedit(&quot;showXY.R&quot;)
| You are really on a roll!
|=======================================
| 30%
| You see both the code and its output! The plots are a little squished, but we see that the active activities
related to walking (shown in
| the two blues and magenta) show more variability than the passive activities (shown in black, red, and
green), particularly in the X
| dimension.
...
|=========================================
| 31%
| The colors are a little hard to distinguish. Just for fun, call the function showMe (we used it in the
Working_with_Colors lesson) which

| displays color vectors. Use the vector 1:6 as its argument, and hopefully this will clarify the colors you
see in the XY comparison plot.
&gt; showMe(1:6)
| You are quite good my friend!
|===========================================
| 33%
| Nice! We just wanted to show you the beauty and difference in colors. The colors at the bottom, black,
red and green, mark the passive
| activities, while the true blues and magenta near the top show the walking activities. Let&#39;s try clustering
to see if we can distinguish
| the activities more.
...
|=============================================
| 34%
| We&#39;ll still focus on the 3 dimensions of mean acceleration. (The plot we just saw looked at the first 2
dimensions.) Create a distance
| matrix, mdist, of the first 3 columns of sub1, by using the R command dist. Use the x[,1:3] notation to
specify the columns.
&gt; mdist &lt;- dist(sub1[,1:3])
| Keep up the great work!
|===============================================
| 36%
| Now create the variable hclustering by calling the R command hclust and passing it mdist as an
argument. This will use the Euclidean
| distance as its default metric.
&gt; hclustering &lt;- hclust(mdist)
| Keep working like that and you&#39;ll get there!
|=================================================
| 38%
| Now call the pretty plotting function (which we&#39;ve already sourced) myplclust with 2 arguments. The first
is hclustering, and the second
| is the argument lab.col set equal to unclass(sub1$activity).
&gt; myplclust(hclustering, lab.col=unclass(sub1$activity))
| Excellent work!
|===================================================
| 39%
| Well that dendrogram doesn&#39;t look too helpful, does it? There&#39;s no clear grouping of colors, except that
active colors (blues and
| magenta) are near each other as are the passive (black, red, and green). So average acceleration
doesn&#39;t tell us much. How about maximum
| acceleration? Let&#39;s look at that for the first subject (in our array sub1) for the X and Y dimensions. These
are in column 10 and 11.
...
|=====================================================
| 41%
| Here they are plotted side by side, X dimension on the left and Y on the right. The x-axis of each show
the 300+ observations and the

| y-axis indicates the maximum acceleration.
...
|=======================================================
| 42%
| From the 2 plots, what separation, if any, do you see?
1: laying generates the most acceleration in the X dimension
2: there is no pattern
3: passive activities mostly fall below the walking activities
4: passive activities generate the most acceleration
Selection: 3
| That&#39;s the answer I was looking for.
|=========================================================
| 44%
| Finally we&#39;re seeing something vaguely interesting! Let&#39;s focus then on the 3 dimensions of maximum
acceleration, stored in columns 10
| through 12 of sub1. Create a new distance matrix, mdist, of these 3 columns of sub1, by using the R
command dist. Again, use the
| x[,10:12] notation to catch the columns.
&gt; mdist &lt;- dist(sub1[,10:12])
| That&#39;s correct!
|===========================================================
| 45%
| Now create the variable hclustering by calling hclust with mdist as the argument.
&gt; hclustering &lt;- hclust(mdist)
| Excellent job!
|=============================================================
| 47%
| Again, call the myplclust with 2 arguments. The first is hclustering, and the second is the argument
lab.col set equal to
| unclass(sub1$activity).
&gt; myplclust(hclustering, lab.col=unclass(sub1$activity))
| You nailed it! Good job!
|===============================================================
| 48%
| Now we see clearly that the data splits into 2 clusters, active and passive activities. Moreover, the light
blue (walking down) is
| clearly distinct from the other walking activities. The dark blue (walking level) also seems to be
somewhat clustered. The passive
| activities, however, seem all jumbled together with no clear pattern visible.
...
|=================================================================
| 50%
| Let&#39;s try some SVD now. Create the variable svd1 by assigning to it the output of a call to the R
command svd. The argument to svd should
| be scale(sub1[,-c(562,563)]). This will remove the last 2 columns from sub1 and scale the data. Recall
that the last 2 columns contain

| activity and subject information which we won&#39;t need.
&gt; svd1 &lt;- svd(scale(sub1[,-c(562,563)]))
| Excellent work!
|===================================================================
| 52%
| To see LEFT singular vectors of sub1, which component of svd1 would we examine?
1: v
2: u
3: d
4: x
Selection: 1
| Almost! Try again.
| One of the choices isn&#39;t even part of the svd output. Recall that singular value decomposition expresses
the matrix X as the product of
| three other matrices, X=UDV. Which of these is leftmost?
1: u
2: v
3: x
4: d
Selection: 3
| You&#39;re close...I can feel it! Try it again.
| One of the choices isn&#39;t even part of the svd output. Recall that singular value decomposition expresses
the matrix X as the product of
| three other matrices, X=UDV. Which of these is leftmost?
1: x
2: v
3: d
4: u
Selection: 4
| Keep up the great work!
|=====================================================================
| 53%
| Call the R command dim with svd1$u as an argument.
&gt; dim(svd1$u)
[1] 347 347
| Keep working like that and you&#39;ll get there!
|=======================================================================
| 55%
| We see that the u matrix is a 347 by 347 matrix. Each row in u corresponds to a row in the matrix sub1.
Recall that in sub1 each row has
| an associated activity.
...

|=========================================================================
| 56%
| Here we&#39;re looking at the 2 left singular vectors of svd1 (the first 2 columns of svd1$u). Each entry of the
columns belongs to a
| particular row with one of the 6 activities assigned to it. We see the activities distinguished by color.
Moving from left to right, the
| first section of rows are green (standing), the second red (sitting), the third black (laying), etc. The first
column of u shows
| separation of the nonmoving (black, red, and green) from the walking activities. The second column is
harder to interpret. However, the
| magenta cluster, which represents walking up, seems separate from the others.
...
|===========================================================================
| 58%
| We&#39;ll try to figure out why that is. To do that we&#39;ll have to find which of the 500+ measurements
(represented by the columns of sub1)
| contributes to the variation of that component. Since we&#39;re interested in sub1 columns, we&#39;ll look at the
RIGHT singular vectors (the
| columns of svd1$v), and in particular, the second one since the separation of the magenta cluster stood
out in the second column of
| svd1$u.
...
|=============================================================================
| 59%
| Here&#39;s a plot of the second column of svd1$v. We used transparency in our plotting but nothing clearly
stands out here. Let&#39;s use
| clustering to find the feature (out of the 500+) which contributes the most to the variation of this second
column of svd1$v.
...
|===============================================================================
| 61%
| Create the variable maxCon by assigning to it the output of the R command which.max using the second
column of svd1$v as an argument.
&gt; maxCon &lt;- which.max(svd1$v[,2])
| You are really on a roll!
|===============================================================================
== | 62%
| Now create a distance matrix mdist by assigning to it the output of the R command dist using 4 columns
of sub1 as the arguments. These 4
| columns are 10 through 12 (10:12) and maxCon. Recall that you&#39;ll have to concatenate these 2 column
expressions when specifying them.
&gt; mdist &lt;- dist(sub1[,c(10:12,maxCon)])
| Keep up the great work!
|===============================================================================
==== | 64%
| Now create hclustering, the output of the R command hclust using mdist as the argument.
&gt; hclustering &lt;- hclust(mdist)
| Perseverance, that&#39;s the answer.

|===============================================================================
====== | 66%
| Call the myplclust with 2 arguments, hclustering, and lab.col set equal to unclass(sub1$activity).
&gt; mdist &lt;- dist(sub1[,c(10:12,maxCon)])
| Nice try, but that&#39;s not exactly what I was hoping for. Try again. Or, type info() for more options.
| Type myplclust(hclustering, lab.col = unclass(sub1$activity)) at the command prompt.
&gt; myplclust(hclustering, lab.col=unclass(sub1$activity))
| Your dedication is inspiring!
|===============================================================================
======== | 67%
| Now we see some real separation. Magenta (walking up) is on the far left, and the two other walking
activities, the two blues, are on the
| far right, but in separate clusters from one another. The nonmoving activities still are jumbled together.
...
|===============================================================================
========== | 69%
| Run the R command names with the argument sub1[maxCon] to see what measurement is associated
with this maximum contributor.
&gt; names(sub1[maxCon])
[1] &quot;fBodyAcc.meanFreq...Z&quot;
| Keep up the great work!
|===============================================================================
============ | 70%
| So the mean body acceleration in the frequency domain in the Z direction is the main contributor to this
clustering phenomenon we&#39;re
| seeing. Let&#39;s move on to k-means clustering to see if this technique can distinguish between the
activities.
...
|===============================================================================
============== | 72%
| Create the variable kClust by assigning to it the output of the R command kmeans with 2 arguments.
The first is sub1 with the last 2
| columns removed. (Recall these don&#39;t have pertinent information for clustering analysis.) The second
argument to kmeans is centers set
| equal to 6, the number of activities we know we have.
&gt; kClust &lt;- kmeans(sub1[,-c(562, 563)], centers=6)
| You are quite good my friend!
|===============================================================================
================ | 73%
| Recall that without specifying coordinates for the cluster centroids (as we did), kmeans will generate
starting points randomly. Here we
| did only 1 random start (the default). To see the output, run the R command table with 2 arguments. The
first is kClust$cluster (part of
| the output from kmeans), and the second is sub1$activity.
&gt; table(kClust$cluster, sub1$activity)

laying sitting standing walk walkdown walkup
1 0 0 0 95 49 0
2 0 34 50 0 0 0
3 14 11 3 0 0 0
4 27 0 0 0 0 0
5 9 2 0 0 0 0
6 0 0 0 0 0 53
| You are amazing!
|===============================================================================
=================== | 75%
| Your exact output will depend on the state of your random number generator. We notice that when we
just run with 1 random start, the
| clusters tend to group the nonmoving activities together in one cluster. The walking activities seem to
cluster individually by
| themselves. You could run the call to kmeans with one random start again and you&#39;ll probably get a
slightly different result, but....
...
|===============================================================================
===================== | 77%
| ... instead call kmeans with 3 arguments, the last of which will tell it to try more random starts and return
the best one. The first 2
| arguments should be the same as before (sub1 with the last 2 columns removed and centers set equal
to 6). The third is nstart set equal
| to 100. Put the result in kClust again.
&gt; kClust &lt;- kmeans(sub1[,-c(562, 563)], centers=6, nstart =100)
| All that hard work is paying off!
|===============================================================================
======================= | 78%
| Again, run the R command table with 2 arguments. The first is kClust$cluster (part of the output from
kmeans), and the second is
| sub1$activity.
&gt; table(kClust$cluster, sub1$activity)
laying sitting standing walk walkdown walkup
1 3 0 0 0 0 53
2 29 0 0 0 0 0
3 18 10 2 0 0 0
4 0 37 51 0 0 0
5 0 0 0 0 49 0
6 0 0 0 95 0 0
| Excellent job!
|===============================================================================
========================= | 80%
| We see that even with 100 random starts, the passive activities tend to cluster together. One of the
clusters contains only laying, but
| in another cluster, standing and sitting group together.
...table(kClust$cluster, sub1$activity)
|===============================================================================
=========================== | 81%
| Use dim to find the dimensions of kClust&#39;s centers. Use the x$y notation to access them.

&gt; dim(kClust$centers)
[1] 6 561
| That&#39;s correct!
|===============================================================================
============================= | 83%
| So the centers are a 6 by 561 array. Sometimes it&#39;s a good idea to look at the features (columns) of
these centers to see if any
| dominate.
...
|===============================================================================
=============================== | 84%
| Create the variable laying and assign to it the output of the call to the R command which with the
argument kClust$size==29.
&gt; laying &lt;- which(kClust$size==29)
| Perseverance, that&#39;s the answer.
|===============================================================================
================================= | 86%
| Now call plot with 3 arguments. The first is kClust$centers[laying,1:12], and the second is pch set to 19.
The third is ylab set equal to
| &quot;Laying Cluster&quot;
&gt; plot(kClust$centers[laying,1:12], pch=19, ylab=&quot;Laying Cluster&quot;)
| That&#39;s the answer I was looking for.
|===============================================================================
=================================== | 88%
| We see the first 3 columns dominate this cluster center. Run names with the first 3 columns of sub1 as
the argument to remind yourself of
| what these columns contain.
&gt; names(sub1[,1:3])
[1] &quot;tBodyAcc.mean...X&quot; &quot;tBodyAcc.mean...Y&quot; &quot;tBodyAcc.mean...Z&quot;
| You&#39;re the best!
|===============================================================================
===================================== | 89%
| So the 3 directions of mean body acceleration seem to have the biggest effect on laying.
...
|===============================================================================
======================================= | 91%
| Create the variable walkdown and assign to it the output of the call to the R command which with the
argument kClust$size==49.
&gt; walkdown &lt;- which(kClust$size==49)
| You are doing so well!
|===============================================================================
========================================= | 92%
| Now call plot with 3 arguments. The first is kClust$centers[walkdown,1:12], and the second is pch set to
19. The third is ylab set equal
| to &quot;Walkdown Cluster&quot;

&gt; plot(kClust$centers[walkdown,1:12], pch=19, ylab=&quot;Walkdown Cluster&quot;)
| That&#39;s correct!
|===============================================================================
=========================================== | 94%
| We see an interesting pattern here. From left to right, looking at the 12 acceleration measurements in
groups of 3, the points decrease
| in value. The X direction dominates, followed by Y then Z. This might tell us something more about the
walking down activity.
...
|===============================================================================
============================================= | 95%
| We&#39;ll wrap up here and hope this example convinced you that real world analysis can be frustrating
sometimes and not always obvious. You
| might have to try several techniques of exploratory data analysis before you hit one that pays off and
leads you to the questioms that
| will be the most promising to explore.
...
|===============================================================================
=============================================== | 97%
| We saw here that the sensor measurements were pretty good at discriminating between the 3 walking
activities, but the passive activities
| were harder to distinguish from one another. These might require more analysis or an entirely different
set of sensory measurements.
...
|===============================================================================
================================================= | 98%
| Congratulations! We hope you enjoyed the 6 activities and 500+ features of this lesson.
...
|===============================================================================
===================================================| 100%
